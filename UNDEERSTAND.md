# Bridge Semantic Coordinate System

## Overview

The Bridge semantic coordinate system provides a principled approach for organizing experiential consciousness into navigable tree structures. Rather than arbitrary clustering, it maps experiences into a 7-dimensional semantic space that reflects how consciousness naturally organizes experience.

This system bridges the gap between:
- **Phenomenological insight**: The unified experiential field described in the Framed Moments framework
- **Technical necessity**: Stable, navigable tree structures for experience organization
- **AI interpretation**: Consistent semantic dimensions that Claude can rate reliably
- **Natural conversation**: Intuitive language for discussing experiential qualities

## The Seven Semantic Dimensions

Each dimension maps to a core aspect of conscious experience, with endpoints aligned along an **Internal/Constrained ↔ External/Expansive** pattern. The coordinate system transforms the seven experiential qualities from the Framed Moments framework into semantic dimensions with natural language scales.

### 1. embodied: thinking ↔ feeling
**Maps to**: Embodied presence (how physicality textures the moment)

| Value | Natural Language | Description |
|-------|-----------------|-------------|
| 0.0 | Mental embodiment | Experience primarily happening in mental/cognitive space |
| 0.1 | Highly mental embodiment | Strongly cognitive, minimal bodily awareness |
| 0.2 | Mostly mental embodiment | Predominantly thinking-based with slight physical awareness |
| 0.3 | Somewhat mental embodiment | Primarily mental but noticeable body presence |
| 0.4 | Slightly mental embodiment | Mostly cognitive with emerging bodily qualities |
| 0.5 | Mixed embodiment | Balanced between mental and felt experience |
| 0.6 | Slightly felt embodiment | Emerging bodily awareness with mental backdrop |
| 0.7 | Somewhat felt embodiment | Primarily feeling-based with mental elements |
| 0.8 | Mostly felt embodiment | Predominantly bodily with minimal mental processing |
| 0.9 | Highly felt embodiment | Strongly sensation-based, minimal cognitive activity |
| 1.0 | Felt embodiment | Experience primarily happening through bodily sensation/emotion |

### 2. focus: detailed ↔ broad
**Maps to**: Attentional flow (direction and quality of awareness)

| Value | Natural Language | Description |
|-------|-----------------|-------------|
| 0.0 | Precise focus | Attention narrowly focused on specific elements |
| 0.1 | Highly precise focus | Very tight attentional scope |
| 0.2 | Mostly precise focus | Predominantly narrow attention with slight breadth |
| 0.3 | Somewhat precise focus | Primarily focused but some peripheral awareness |
| 0.4 | Slightly precise focus | Mostly focused with emerging breadth |
| 0.5 | Balanced focus | Even mix of focused and broad attention |
| 0.6 | Slightly wide focus | Emerging breadth with focused undertones |
| 0.7 | Somewhat wide focus | Primarily broad with some focal points |
| 0.8 | Mostly wide focus | Predominantly broad attention with minimal focus |
| 0.9 | Highly wide focus | Very broad attentional scope |
| 1.0 | Wide focus | Attention spread across wide scope of awareness |

### 3. mood: closed ↔ open
**Maps to**: Affective atmosphere (emotional coloring of experience)

| Value | Natural Language | Description |
|-------|-----------------|-------------|
| 0.0 | Guarded mood | Emotional state that is defensive, protected, contractive |
| 0.1 | Highly guarded mood | Very defensive emotional stance |
| 0.2 | Mostly guarded mood | Predominantly protective with slight openness |
| 0.3 | Somewhat guarded mood | Primarily defensive but some receptivity |
| 0.4 | Slightly guarded mood | Mostly protective with emerging openness |
| 0.5 | Neutral mood | Balanced between guarded and receptive states |
| 0.6 | Slightly receptive mood | Emerging openness with protective undertones |
| 0.7 | Somewhat receptive mood | Primarily open with some defensiveness |
| 0.8 | Mostly receptive mood | Predominantly open with minimal guardedness |
| 0.9 | Highly receptive mood | Very open emotional stance |
| 1.0 | Receptive mood | Emotional state that is open, available, expansive |

### 4. purpose: focused ↔ wandering
**Maps to**: Purposive momentum (directedness or drift of the moment)

| Value | Natural Language | Description |
|-------|-----------------|-------------|
| 0.0 | Directed purpose | Clear intentional direction, goal-oriented momentum |
| 0.1 | Highly directed purpose | Very strong goal orientation |
| 0.2 | Mostly directed purpose | Predominantly goal-focused with slight exploration |
| 0.3 | Somewhat directed purpose | Primarily focused but some wandering |
| 0.4 | Slightly directed purpose | Mostly goal-oriented with emerging exploration |
| 0.5 | Flexible purpose | Balanced between directed and exploratory movement |
| 0.6 | Slightly exploratory purpose | Emerging wandering with directed undertones |
| 0.7 | Somewhat exploratory purpose | Primarily wandering with some direction |
| 0.8 | Mostly exploratory purpose | Predominantly exploratory with minimal direction |
| 0.9 | Highly exploratory purpose | Very open-ended, wandering movement |
| 1.0 | Exploratory purpose | Open-ended drift, curiosity-driven movement |

### 5. space: here ↔ there
**Maps to**: Spatial situation (lived sense of place and position)

| Value | Natural Language | Description |
|-------|-----------------|-------------|
| 0.0 | Immediate space | Spatially grounded in immediate proximity |
| 0.1 | Highly immediate space | Very close, intimate spatial awareness |
| 0.2 | Mostly immediate space | Predominantly local with slight distance |
| 0.3 | Somewhat immediate space | Primarily here-focused but some distant awareness |
| 0.4 | Slightly immediate space | Mostly local with emerging distance |
| 0.5 | Transitional space | Balanced between immediate and distant orientation |
| 0.6 | Slightly distant space | Emerging distance with local undertones |
| 0.7 | Somewhat distant space | Primarily distant with some immediate awareness |
| 0.8 | Mostly distant space | Predominantly distant with minimal local focus |
| 0.9 | Highly distant space | Very far-reaching spatial awareness |
| 1.0 | Distant space | Spatially oriented toward distant or expanded locations |

### 6. time: past ↔ future
**Maps to**: Temporal flow (how past and future inhabit the present)

| Value | Natural Language | Description |
|-------|-----------------|-------------|
| 0.0 | Historical time | Temporal orientation toward memory, retrospection |
| 0.1 | Highly historical time | Very past-focused temporal awareness |
| 0.2 | Mostly historical time | Predominantly retrospective with slight forward sense |
| 0.3 | Somewhat historical time | Primarily past-oriented but some future awareness |
| 0.4 | Slightly historical time | Mostly retrospective with emerging future sense |
| 0.5 | Present time | Balanced temporal awareness, neither past nor future dominant |
| 0.6 | Slightly anticipatory time | Emerging future orientation with past undertones |
| 0.7 | Somewhat anticipatory time | Primarily future-oriented with some retrospection |
| 0.8 | Mostly anticipatory time | Predominantly forward-looking with minimal past focus |
| 0.9 | Highly anticipatory time | Very future-focused temporal awareness |
| 1.0 | Anticipatory time | Temporal orientation toward anticipation, projection |

### 7. others: alone ↔ together
**Maps to**: Intersubjective field (how others' presence or absence matters)

| Value | Natural Language | Description |
|-------|-----------------|-------------|
| 0.0 | Individual others | Experience of solitary, individual consciousness |
| 0.1 | Highly individual others | Very solitary, minimal social awareness |
| 0.2 | Mostly individual others | Predominantly individual with slight social sense |
| 0.3 | Somewhat individual others | Primarily solitary but some collective awareness |
| 0.4 | Slightly individual others | Mostly individual with emerging social connection |
| 0.5 | Connected others | Balanced between individual and collective experience |
| 0.6 | Slightly collective others | Emerging social connection with individual undertones |
| 0.7 | Somewhat collective others | Primarily social with some individual elements |
| 0.8 | Mostly collective others | Predominantly collective with minimal individual focus |
| 0.9 | Highly collective others | Very socially connected, minimal individual awareness |
| 1.0 | Collective others | Experience of shared, collective, or social consciousness |

## Design Principles

### 1. Semantic Distinctness
Each dimension uses completely distinct vocabulary to avoid overlap:
- **embodied**: mental/felt (cognitive vs bodily)
- **focus**: precise/wide (attention scope)
- **mood**: guarded/receptive (emotional stance)
- **purpose**: directed/exploratory (intentional style)
- **space**: immediate/distant (spatial proximity)
- **time**: historical/anticipatory (temporal orientation)
- **others**: individual/collective (social scope)

### 2. Consistent Alignment
All dimensions follow the Internal/Constrained ↔ External/Expansive pattern:
- **Left side (0.0)**: Internal, constrained, narrow, contained
- **Right side (1.0)**: External, expansive, broad, outward

### 3. Natural Language Interface
Claude describes experiences conversationally rather than mechanically:
- ✅ "I notice mostly felt embodiment, along with directed purpose and anticipatory time"
- ✅ "This feels like wide focus with receptive mood"
- ❌ "Coordinates: (0.8, 0.9, 0.7, 0.1, 0.2, 0.8, 0.3)"

### 4. Phenomenological Grounding
Dimensions directly correspond to the experiential structure identified in consciousness research, not arbitrary technical categories.

## Implementation

### Experience Capture with Natural Language Interface
```typescript
// Primary experiences (direct, immediate)
remember({
  source: "Coffee tastes good",
  experiencer: "Human", 
  experience: ["felt:embodiment:1.0"]
  // Bridge converts to embedded notation automatically
})

remember({
  source: "Thinking through the strategy for tomorrow's presentation",
  experiencer: "Human",
  experience: ["mental:embodiment:0.0", "directed:purpose:0.0", "anticipatory:time:1.0"]
  // Bridge handles conversion from natural language input
})

// Reflections (insights, realizations about other experiences)
remember({
  source: "Realized I avoid taking action, stuck in observation mode",
  experiencer: "Human",
  experience: ["mental:embodiment:0.0", "anticipatory:time:1.0"],
  reflects: ["exp_123", "exp_456", "exp_789"]  // This insight reflects on these experiences
})

remember({
  source: "I'm more creative when I feel embodied and open",
  experiencer: "Human", 
  experience: ["mental:embodiment:0.0", "directed:purpose:0.0"],
  reflects: ["exp_234", "exp_567"]  // Pattern recognition across creative moments
})

// Complex experiences
remember({
  source: "Shoulders killing me but we're close to breakthrough",
  experiencer: "Human",
  experience: ["felt:embodiment:1.0", "directed:purpose:0.0", "anticipatory:time:1.0", "neutral:mood:0.5"]
  // Bridge converts all natural language to embedded notation
})

remember({
  source: "Team meeting went better than expected",
  experiencer: "Human",
  experience: ["collective:others:1.0", "receptive:mood:1.0", "historical:time:0.0"]
  // All conversions handled automatically by Bridge
})

// Claude responds naturally using both natural language and coordinates:
// "I notice felt:embodiment:1.0 with directed:purpose:0.0 and anticipatory:time:1.0"
// OR: "Strong felt embodiment (1.0) with directed purpose (0.0) and future focus (1.0)"
```

**Natural Language Interface:**
- **User input**: Natural language experience arrays that Bridge converts
- **Bridge processing**: Automatic conversion to embedded notation format  
- **Claude access**: Both natural language and coordinate values in one string
- **Conversational output**: Claude can reference either component as needed

**Two-Layer Architecture:**
- **Primary experiences**: Direct, immediate consciousness ("what happened")
- **Reflections**: Insights, realizations, patterns about other experiences ("what you think about what happened")  
- **Automatic detection**: `reflects` field exists = reflection, otherwise primary
- **Natural conversation**: Claude refers to "reflections" and "insights" rather than technical terms

**Capture Principles:**
- **Minimum requirement**: At least 1 prominent quality (otherwise don't remember)
- **No fabrication**: Only capture dimensions that are genuinely present in the source
- **No over-interpretation**: Avoid forcing meaning where none exists
- **Quality over quantity**: Better to capture 2 accurate dimensions than 7 fabricated ones
- **Natural language**: Use quality descriptions from the 7-dimensional framework
- **Reflection linking**: Use `reflects` field to connect insights to their source experiences

### Projection System: bridge.understand()

The coordinate system enables powerful experiential analysis through a simple interface. **Single dimensions provide specialized lenses into consciousness, while multi-dimensional projections reveal cognitive patterns and decision-making frameworks.** Content embeddings automatically create semantic subclusters within coordinate groups, revealing the purposive themes and content patterns that organize experience.

## Cognitive Framework Analysis

### Single-Dimension Specialized Lenses

Each dimension provides a complete analytical lens with rich content themes:

```typescript
// PURPOSE: Complete purposive life map
bridge.understand("purpose")
// → Directed purpose: "Creative work", "Professional goals", "Skill building"  
// → Exploratory purpose: "Discovery learning", "Social exploration", "Creative experimentation"

// FOCUS: Attention architecture analysis  
bridge.understand("focus")
// → Precise focus: "Deep work sessions", "Technical problem solving", "Detailed craftsmanship"
// → Wide focus: "Strategic planning", "Pattern synthesis", "Contextual awareness"

// MOOD: Emotional territory mapping
bridge.understand("mood") 
// → Guarded mood: "Protective work states", "Boundary setting", "Cautious exploration"
// → Receptive mood: "Creative flow", "Intimate conversations", "Learning openness"

// EMBODIED: Consciousness mode analysis
bridge.understand("embodied")
// → Mental embodiment: "Strategic thinking", "Abstract problem solving", "Conceptual work"
// → Felt embodiment: "Physical creativity", "Intuitive knowing", "Somatic awareness"

// TIME: Temporal orientation patterns  
bridge.understand("time")
// → Historical time: "Reflection practices", "Learning from experience", "Memory processing"
// → Anticipatory time: "Future planning", "Goal visualization", "Possibility exploration"

// OTHERS: Social interaction mapping
bridge.understand("others")
// → Individual others: "Solo work", "Personal reflection", "Independent learning"
// → Collective others: "Team collaboration", "Community building", "Shared activities"

// SPACE: Spatial awareness analysis
bridge.understand("space")
// → Immediate space: "Focused presence", "Intimate interactions", "Detailed work" 
// → Distant space: "Big picture thinking", "Environmental awareness", "Expanded perspective"
```

### Two-Dimensional Cognitive Models

```typescript
// OODA Loop: Decision-making cycle analysis
bridge.understand(["focus", "time"])
// → Observe (precise + historical): Detailed attention to immediate data
// → Orient (wide + historical): Pattern synthesis from past experience  
// → Decide (wide + anticipatory): Broad evaluation of future options
// → Act (precise + anticipatory): Specific execution of plans

// Flow State Mapping: Optimal experience conditions
bridge.understand(["embodied", "mood"])
// → Felt + receptive: "Creative flow", "Physical mastery", "Intuitive breakthroughs"
// → Mental + receptive: "Intellectual flow", "Learning absorption", "Conceptual insights"
// → Felt + guarded: "Protective embodiment", "Physical boundaries", "Cautious movement"
```

### Human-Centered Design Framework (3D Analysis)

Three-dimensional analysis reveals complete design thinking and user experience patterns:

```typescript
// Complete UX Design Process Mapping
bridge.understand(["time", "focus", "others"])

// Claude analyzes and responds:
// "Your design thinking process shows clear patterns across all eight UX phases:
//  
//  **Research Phase (Historical + Precise + Individual)**:
//  └── User Interviews: 'Deep conversation with single user about pain points'
//  └── Persona Development: 'Detailed analysis of individual user behaviors'  
//  └── Journey Mapping: 'Tracing specific user's step-by-step experience'
//  
//  **Market Analysis (Historical + Wide + Individual)**:
//  └── Competitive Analysis: 'Broad survey of existing solutions for users'
//  └── Trend Research: 'Understanding individual user behavior patterns over time'
//  └── Context Mapping: 'Wide view of individual user's environment and constraints'
//  
//  **User Behavior Study (Historical + Precise + Collective)**:
//  └── Usability Testing: 'Detailed observation of group user sessions'
//  └── A/B Testing: 'Precise measurement of collective user responses'
//  └── Analytics Deep-Dive: 'Focused analysis of group usage patterns'
//  
//  **Market Research (Historical + Wide + Collective)**:
//  └── Industry Analysis: 'Broad understanding of market and user ecosystem'
//  └── Demographic Research: 'Wide patterns across user populations'
//  └── Ecosystem Mapping: 'Understanding collective user behaviors and trends'
//  
//  **Ideation (Anticipatory + Precise + Individual)**:
//  └── User Task Design: 'Specific future interactions for individual users'
//  └── Feature Specification: 'Detailed future functionality for user needs'
//  └── Interaction Design: 'Precise future user interface behaviors'
//  
//  **Experience Visioning (Anticipatory + Wide + Individual)**:
//  └── Service Design: 'Broad future experience for individual user journeys'
//  └── Scenario Planning: 'Wide range of future user contexts and needs'
//  └── Experience Strategy: 'Comprehensive individual user experience vision'
//  
//  **Prototyping (Anticipatory + Precise + Collective)**:
//  └── User Testing: 'Specific future interactions tested with groups'
//  └── Workflow Design: 'Detailed collective user processes and systems'
//  └── System Design: 'Precise future collective user experiences'
//  
//  **Strategic UX (Anticipatory + Wide + Collective)**:
//  └── Ecosystem Design: 'Broad future vision for collective user experiences'
//  └── Platform Strategy: 'Wide anticipatory design for user communities'
//  └── Vision Setting: 'Comprehensive future state for user populations'
//  
//  This shows you operate across the complete human-centered design spectrum,
//  with particular strength in historical analysis and anticipatory individual design."
```

### Complete Experiential Overview

```typescript
// Complete consciousness map showing all patterns and themes
bridge.understand()
// Shows entire 7D coordinate space organized by:
// 1. Coordinate clusters (phenomenological groupings)
// 2. Content themes within each cluster (semantic purposes)  
// 3. Specific experiences within each theme
```

## Core Parameters

```typescript
bridge.understand(
  dimensions?: string | string[],  // Single dimension, array, or blank for overview
  options?: {
    filter?: {
      reflects?: boolean | "all",           // Include reflections (default: primary only)
      reflects_on?: string,                 // Insights about specific experience
      timespan?: string,                    // Chrono-node expressions
      [dimension]: {min?: number, max?: number}  // Coordinate ranges
    },
    as?: "groups" | "sequence"              // Clustering vs temporal analysis
  }
)
```

## How Content Embeddings Work

**Step 1: Automatic Embedding Generation**
- During `remember()`, Bridge generates content embeddings using Xenova (browser-based ML)
- Each experience source gets a 300-dimension semantic vector
- Same embedding system used by recall for content similarity

**Step 2: Coordinate Clustering** 
- Bridge converts natural language qualities to 7D coordinates using embedded notation
- Groups experiences by coordinate similarity (phenomenological patterns)
- Creates initial clusters like "directed:purpose:0.0 + receptive:mood:1.0"

**Step 3: Content Theme Subdivision**
- Within each coordinate cluster, embedding similarity creates subclusters
- Reveals semantic themes: "Creative work", "Professional goals", "Skill building"
- Each theme contains experiences with similar content but same phenomenology

**Example Process:**
```typescript
// 1. Experiences with similar coordinates cluster together:
"Directed purpose + receptive mood" cluster contains:
- "Guitar practice session flowing beautifully" 
- "Writing breakthrough after struggling"
- "Pottery class finding the rhythm"
- "Presenting ideas and feeling heard"
- "Leading meeting with clear vision"

// 2. Embedding similarity subdivides into content themes:
→ Creative Flow: Guitar, writing, pottery sessions
→ Professional Expression: Presenting, meeting leadership  
→ Skill Development: Practice sessions, technique building

// 3. Claude presents both structure and themes:
"Your directed:purpose:0.0 + receptive:mood:1.0 experiences show two main content themes:
Creative Flow and Professional Expression..."
```

**Technical Implementation:**
- **Embedding model**: Xenova transformers (runs locally, no API costs)
- **Vector storage**: 300D embeddings stored with each experience
- **Clustering**: Cosine similarity within coordinate groups
- **Content extraction**: Semantic themes extracted from embedding clusters

## Reflection Analysis (Opt-in)

```typescript
// Meta-cognitive development analysis (separate from primary experiences)
bridge.understand("purpose", {filter: {reflects: true}})
// Shows how insights about purpose develop over time

// Reflection chain analysis
bridge.understand([], {filter: {reflects_on: "exp_123"}})
// What insights emerged from specific breakthrough experience?

// Complete consciousness (primary + reflections)
bridge.understand("mood", {filter: {reflects: "all"}})
// How emotional experiences and insights about them interact
```

**Clean Separation:**
- **Default**: Primary experiences only (stable experiential analysis)
- **Explicit opt-in**: Reflections analyzed separately to avoid contamination
- **Combined analysis**: Available but requires explicit request

**Handling Sparse Data:**
- Experiences missing requested dimensions are excluded from projections
- Only patterns from genuinely captured qualities emerge
- More reliable insights from honest, sparse data than fabricated complete data
- Claude naturally adapts analysis to available data density

**Smart Analysis:**
- Claude interprets patterns naturally regardless of visualization
- 1D projections reveal temporal or dimensional trends
- 2D projections show correlations and clustering (including cognitive patterns like OODA)
- 3D+ projections enable hierarchical navigation through experience space

### OODA Loop Analysis (2D Projection)

```typescript
// Decision-making cycle analysis: focus vs time
bridge.understand(["focus", "time"])

// Claude analyzes the coordinate patterns and responds:
// "I see distinct clustering patterns in your focus-time space:
//  
//  **Bottom-left cluster (Precise + Historical)**: Heavy concentration here - 
//  'noticed the exact tension in my shoulders during yesterday's meeting'
//  This is your Observation mode - you're precisely focused on 
//  immediate data from recent experiences.
//  
//  **Bottom-right region (Wide + Historical)**: Good representation -
//  'thinking about how all these interactions connect to larger patterns'
//  This is Orientation - synthesizing past data with broad awareness.
//  
//  **Top-right area (Wide + Anticipatory)**: Some activity -
//  'considering all the different ways tomorrow could unfold'  
//  This is Decision-making - broad evaluation of future possibilities.
//  
//  **Top-left sparse area (Precise + Anticipatory)**: Very few experiences -
//  'executing the specific action plan we decided on'
//  This is Action - your least occupied quadrant.
//  
//  The pattern suggests you're excellent at observation and decent at 
//  orientation, but you may be avoiding the precise future space 
//  where decisions become specific actions."
```

**Natural Quadrant Recognition:**
- **Observe**: focus: 0.0-0.4, time: 0.0-0.4 (precise + historical)
- **Orient**: focus: 0.6-1.0, time: 0.0-0.4 (wide + historical)
- **Decide**: focus: 0.6-1.0, time: 0.6-1.0 (wide + anticipatory)  
- **Act**: focus: 0.0-0.4, time: 0.6-1.0 (precise + anticipatory)

### Navigation Examples
```typescript
// Temporal tracking with chrono-node - only experiences with time data
bridge.understand(["time"], {
  as: "sequence",
  filter: {timespan: "last 3 days"}
})

bridge.understand("mood", {
  as: "sequence",
  filter: {timespan: "this morning"}
})

// Social-emotional mapping - only experiences with both dimensions
bridge.understand(["others", "mood"], {
  as: "groups"
})

// Embodied experiences with purpose analysis
bridge.understand(["focus", "purpose"], {
  filter: {embodied: {min: 0.7}, timespan: "since Tuesday"},
  as: "groups"
})

// Multi-dimensional analysis with hierarchical clustering
bridge.understand(["embodied", "focus", "others"], {
  as: "groups",
  filter: {timespan: "between Monday and Wednesday"}
})

// Filtered projections with natural time expressions
bridge.understand(["embodied", "time"], {
  filter: {
    embodied: {min: 0.7},
    timespan: "yesterday afternoon"
  },
  as: "groups"
})
```

**Chrono-Node Time Expressions:**
- **Relative**: "last 3 days", "past week", "next month"
- **Absolute**: "this morning", "yesterday afternoon", "since Tuesday"  
- **Contextual**: "during the meeting", "after lunch", "before the call"
- **Ranges**: "between Monday and Wednesday", "from last Tuesday until Friday"

**Data Handling Benefits:**
- **Honest patterns**: Only show correlations that actually exist in captured data
- **Adaptive analysis**: Claude adjusts insights based on data availability  
- **Quality focus**: Sparse but accurate data reveals more reliable patterns than fabricated completeness
- **Natural filtering**: Missing dimensions automatically exclude irrelevant experiences from projections
- **Deterministic processing**: Clear inputs enable reliable caching and consistent results

## OODA Loop Example

The coordinate system naturally captures cognitive cycles:

1. **Observe**: mostly felt embodiment, precise focus, historical time
2. **Orient**: mixed embodiment, wide focus, historical time  
3. **Decide**: mental embodiment, wide focus, anticipatory time
4. **Act**: felt embodiment, precise focus, anticipatory time

## Benefits

### For Human Users
- **Intuitive navigation**: Explore experience along meaningful phenomenological dimensions
- **Automatic content themes**: Discover semantic patterns within coordinate clusters without interface complexity
- **Complete consciousness map**: Blank calls reveal entire experiential landscape with both structure and themes
- **Clean separation**: bridge for coordinate analysis, recall.similar() for content discovery - no confusion
- **Progressive exploration**: Start with overview, drill down to specific coordinate regions

### For AI Systems
- **Consistent interpretation**: Clear semantic dimensions for reliable coordinate rating
- **Natural expression**: Conversational descriptions of both phenomenological structure and content themes
- **Automatic refinement**: Content embeddings enhance coordinate clustering without interface bloat
- **Embedding reuse**: Leverage existing recall embedding infrastructure for bridge content analysis
- **Rich insights**: Combine interpretable structure with semantic depth seamlessly

### For the Bridge System
- **Clean architecture**: Single coordinate interface with automatic content layer underneath
- **Scalable processing**: Accommodates sparse coordinate data with embedding refinement
- **Emergent intelligence**: Patterns emerge from both phenomenological structure and semantic content
- **System integration**: Uses existing recall embeddings without duplicating infrastructure
- **Deterministic simplicity**: Maintains clean interface while adding analytical depth

## Future Directions

### Enhanced Natural Language
- Context-sensitive descriptor selection
- Personalized vocabulary adaptation
- Multi-cultural semantic mappings

### Advanced Navigation
- Semantic trajectory analysis
- Experiential state prediction
- Natural language querying

### Research Applications
- Cross-cultural experiential mapping
- Therapeutic pattern identification
- Consciousness development tracking

## remember() Tool Interface

The `remember()` function captures experiences in the Bridge system using natural language descriptions that are automatically converted to coordinates for mathematical analysis.

### Core Parameters

```typescript
remember({
  source: string,           // The experiential content (required)
  experiencer: string,      // Who had the experience (required)
  experience: string[],     // Natural language qualities array (required)
  reflects?: string[]       // Experience IDs this reflects on (optional)
})
```

### Parameter Details

**source** (required): The raw experiential content
- First-person present-tense descriptions work best
- Can be from any input source (voice, text, journals, etc.)
- Should contain genuine experiential content, not abstract concepts

**experiencer** (required): Who had the experience  
- "Human" for user experiences
- Could be other identifiers for multi-user systems
- Enables filtering and attribution in analysis

**experience** (required): Natural language quality descriptors
- Array of experiential qualities: `["felt embodiment", "directed purpose"]`
- Use natural language from the 7-dimensional framework
- Only include qualities genuinely prominent in the source
- Bridge automatically converts to coordinates for mathematical operations

**reflects** (optional): Links to other experiences
- Array of experience IDs: `["exp_123", "exp_456"]`
- Automatically marks this as a reflection rather than primary experience
- Creates traceable chains of insight development
- Enables analysis of how insights emerge from patterns

## Natural Language to Coordinate Conversion

Bridge uses exact deterministic mapping for consistent natural language → coordinate conversion. **70 total labels across 7 dimensions, 10 labels per dimension using our established vocabulary.**

### Complete Conversion Table

```typescript
// EMBODIED DIMENSION (mental ↔ felt)
"mental:embodiment:0.0"
"highly:mental:embodiment:0.1"  
"mostly:mental:embodiment:0.2"
"somewhat:mental:embodiment:0.3"
"slightly:mental:embodiment:0.4"
"mixed:embodiment:0.5"
"slightly:felt:embodiment:0.6"
"somewhat:felt:embodiment:0.7"
"mostly:felt:embodiment:0.8"
"highly:felt:embodiment:0.9"
"felt:embodiment:1.0"

// FOCUS DIMENSION (precise ↔ wide)
"precise:focus:0.0"
"highly:precise:focus:0.1"
"mostly:precise:focus:0.2"  
"somewhat:precise:focus:0.3"
"slightly:precise:focus:0.4"
"balanced:focus:0.5"
"slightly:wide:focus:0.6"
"somewhat:wide:focus:0.7"
"mostly:wide:focus:0.8"
"highly:wide:focus:0.9"
"wide:focus:1.0"

// MOOD DIMENSION (guarded ↔ receptive)
"guarded:mood:0.0"
"highly:guarded:mood:0.1"
"mostly:guarded:mood:0.2"
"somewhat:guarded:mood:0.3"
"slightly:guarded:mood:0.4"
"neutral:mood:0.5"
"slightly:receptive:mood:0.6"
"somewhat:receptive:mood:0.7"
"mostly:receptive:mood:0.8"
"highly:receptive:mood:0.9"
"receptive:mood:1.0"

// PURPOSE DIMENSION (directed ↔ exploratory)
"directed:purpose:0.0"
"highly:directed:purpose:0.1"
"mostly:directed:purpose:0.2"
"somewhat:directed:purpose:0.3"
"slightly:directed:purpose:0.4"
"flexible:purpose:0.5"
"slightly:exploratory:purpose:0.6"
"somewhat:exploratory:purpose:0.7"
"mostly:exploratory:purpose:0.8"
"highly:exploratory:purpose:0.9"
"exploratory:purpose:1.0"

// SPACE DIMENSION (immediate ↔ distant)
"immediate:space:0.0"
"highly:immediate:space:0.1"
"mostly:immediate:space:0.2"
"somewhat:immediate:space:0.3"
"slightly:immediate:space:0.4"
"transitional:space:0.5"
"slightly:distant:space:0.6"
"somewhat:distant:space:0.7"
"mostly:distant:space:0.8"
"highly:distant:space:0.9"
"distant:space:1.0"

// TIME DIMENSION (historical ↔ anticipatory)
"historical:time:0.0"
"highly:historical:time:0.1"
"mostly:historical:time:0.2"
"somewhat:historical:time:0.3"
"slightly:historical:time:0.4"
"present:time:0.5"
"slightly:anticipatory:time:0.6"
"somewhat:anticipatory:time:0.7"
"mostly:anticipatory:time:0.8"
"highly:anticipatory:time:0.9"
"anticipatory:time:1.0"

// OTHERS DIMENSION (individual ↔ collective)
"individual:others:0.0"
"highly:individual:others:0.1"
"mostly:individual:others:0.2"
"somewhat:individual:others:0.3"
"slightly:individual:others:0.4"
"connected:others:0.5"
"slightly:collective:others:0.6"
"somewhat:collective:others:0.7"
"mostly:collective:others:0.8"
"highly:collective:others:0.9"
"collective:others:1.0"
```

### Embedded Notation Benefits

**Hierarchical Structure**: `modifier:category:value` creates consistent, parseable format
- **Base terms**: "felt:embodiment:1.0", "mental:embodiment:0.0"  
- **Gradations**: "mostly:felt:embodiment:0.8", "slightly:receptive:mood:0.6"
- **Midpoints**: "mixed:embodiment:0.5", "neutral:mood:0.5"

**Dual Access**: Claude can reference either natural language or numeric value from same string
- Conversational: "I notice felt embodiment with directed purpose"
- Precise: "The 1.0 embodied and 0.0 purpose coordinates show..."
- Combined: "Your felt embodiment (1.0) pairs with directed purpose (0.0)"

**Perfect Determinism**: Each label maps to exactly one coordinate value, eliminating ambiguity while maintaining natural language flow.

### Experience Types

**Primary Experiences** (no reflects field):
- Direct, immediate consciousness
- "What happened" in real-time or recent memory
- Forms the foundational experiential data
- Example: "Coffee tastes good", "Shoulders tense during meeting"

**Reflections** (has reflects field):
- Insights, realizations, patterns about other experiences
- "What you think about what happened"
- Meta-cognitive layer built on primary experiences  
- Example: "Realized I avoid action", "I'm more creative when embodied"

### Usage Examples

```typescript
// Simple primary experience
remember({
  source: "Morning coffee ritual feels grounding",
  experiencer: "Human",
  experience: ["felt embodiment", "receptive mood"]
})

// Complex reflection linking multiple insights
remember({
  source: "My breakthrough moments always involve taking embodied action despite mental resistance",
  experiencer: "Human", 
  experience: ["mental embodiment", "directed purpose", "anticipatory time"],
  reflects: ["exp_101", "exp_87", "exp_234", "exp_156"]  // Links to 4 breakthrough experiences
})

// Multi-dimensional primary experience
remember({
  source: "Leading the team through crisis felt intense but connecting",
  experiencer: "Human",
  experience: ["felt embodiment", "collective others", "directed purpose", "receptive mood"]
})
```

### Integration with bridge.understand()

The natural language interface enables sophisticated filtering and analysis:

```typescript
// Primary experiences only (default)
bridge.understand(["embodied", "mood"])

// Reflections only  
bridge.understand(["embodied", "mood"], {
  filter: {reflects: true}
})

// All experiences (primary + reflections)
bridge.understand(["embodied", "mood"], {
  filter: {reflects: "all"}  
})

// Trace reflection chains
bridge.understand(["purpose"], {
  filter: {reflects_on: "exp_123"}  // Reflections that reference this experience
})
```

This creates a natural interface where users think and communicate in experiential terms while the system maintains mathematical precision for sophisticated analysis and pattern recognition.